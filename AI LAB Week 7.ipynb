{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Feature Selection with GA and PSO\n",
    "\n",
    "In this notebook, we will:\n",
    "1. Load and preprocess a CSV classification dataset.\n",
    "2. Apply Genetic Algorithm (GA) for feature selection.\n",
    "3. Apply Particle Swarm Optimization (PSO) for feature selection.\n",
    "4. Compare the results of GA and PSO in terms of accuracy, number of features selected, and computation time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load dataset\n",
    "def load_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    return data\n",
    "\n",
    "# Preprocess data\n",
    "def preprocess_data(data):\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = pd.DataFrame(imputer.fit_transform(data.select_dtypes(include=[float, int])), columns=data.select_dtypes(include=[float, int]).columns)\n",
    "    \n",
    "    # Encode categorical variables\n",
    "    categorical_columns = data.select_dtypes(include=[object]).columns\n",
    "    le = LabelEncoder()\n",
    "    for col in categorical_columns:\n",
    "        data_imputed[col] = le.fit_transform(data[col])\n",
    "    \n",
    "    return data_imputed\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "file_path = 'weather_classification_data.csv'  # Update this with the path to your dataset\n",
    "data = load_data(file_path)\n",
    "data = preprocess_data(data)\n",
    "\n",
    "# Define features and target\n",
    "X = data.drop(columns=['Weather Type'])\n",
    "y = data['Weather Type']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.9015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train a Decision Tree Classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Predict and calculate accuracy\n",
    "y_pred = dt.predict(X_test)\n",
    "baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply Genetic Algorithm for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (GA): [0, 3, 4, 5]\n",
      "GA Accuracy: 0.8780\n"
     ]
    }
   ],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Define the fitness function for GA\n",
    "def evaluate(individual):\n",
    "    selected_features = [index for index in range(len(individual)) if individual[index] == 1]\n",
    "    if len(selected_features) == 0:\n",
    "        return 0,\n",
    "    \n",
    "    X_train_selected = X_train.iloc[:, selected_features]\n",
    "    X_test_selected = X_test.iloc[:, selected_features]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train_selected, y_train)\n",
    "    y_pred = dt.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mutual_info = mutual_info_classif(X_train, y_train)\n",
    "    relevancy = np.sum(mutual_info[selected_features]) / len(selected_features)\n",
    "    \n",
    "    return accuracy + relevancy\n",
    "\n",
    "# Setup GA\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", np.random.randint, 2)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=len(X_train.columns))\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate)\n",
    "\n",
    "population = toolbox.population(n=50)\n",
    "NGEN = 20\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.2\n",
    "\n",
    "# Run GA\n",
    "for gen in range(NGEN):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb=CXPB, mutpb=MUTPB)\n",
    "    fits = list(map(toolbox.evaluate, offspring))\n",
    "    \n",
    "    for fit, ind in zip(fits, offspring):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    population[:] = toolbox.select(offspring, len(population))\n",
    "\n",
    "best_individual_ga = tools.selBest(population, k=1)[0]\n",
    "selected_features_ga = [index for index in range(len(best_individual_ga)) if best_individual_ga[index] == 1]\n",
    "print(f\"Selected Features (GA): {selected_features_ga}\")\n",
    "\n",
    "# Evaluate GA results\n",
    "X_train_selected_ga = X_train.iloc[:, selected_features_ga]\n",
    "X_test_selected_ga = X_test.iloc[:, selected_features_ga]\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_selected_ga, y_train)\n",
    "y_pred_ga = dt.predict(X_test_selected_ga)\n",
    "selected_accuracy_ga = accuracy_score(y_test, y_pred_ga)\n",
    "print(f\"GA Accuracy: {selected_accuracy_ga:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Apply Particle Swarm Optimization (PSO) for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyswarm in c:\\users\\umer khan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\umer khan\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyswarm) (1.24.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'tuple'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m ub \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(X\u001b[38;5;241m.\u001b[39mcolumns)  \u001b[38;5;66;03m# Upper bounds for the features\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Run PSO\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m xopt, fopt \u001b[38;5;241m=\u001b[39m \u001b[43mpso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfitness_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mub\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswarmsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m selected_features_pso \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(xopt)) \u001b[38;5;28;01mif\u001b[39;00m xopt[i] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected Features (PSO): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_features_pso\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Umer Khan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyswarm\\pso.py:111\u001b[0m, in \u001b[0;36mpso\u001b[1;34m(func, lb, ub, ieqcons, f_ieqcons, args, kwargs, swarmsize, omega, phip, phig, maxiter, minstep, minfunc, debug)\u001b[0m\n\u001b[0;32m    108\u001b[0m p[i, :] \u001b[38;5;241m=\u001b[39m x[i, :]\n\u001b[0;32m    110\u001b[0m \u001b[38;5;66;03m# Calculate the objective's value at the current particle's\u001b[39;00m\n\u001b[1;32m--> 111\u001b[0m \u001b[43mfp\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m obj(p[i, :])\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# At the start, there may not be any feasible starting point, so just\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;66;03m# give it a temporary \"best\" point since it's likely to change\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from pyswarm import pso\n",
    "\n",
    "# Define the fitness function for PSO\n",
    "def fitness_function(x):\n",
    "    selected_features = [i for i in range(len(x)) if x[i] > 0.5]\n",
    "    if len(selected_features) == 0:\n",
    "        return 1.0,\n",
    "    \n",
    "    X_train_selected = X_train.iloc[:, selected_features]\n",
    "    X_test_selected = X_test.iloc[:, selected_features]\n",
    "    \n",
    "    dt = DecisionTreeClassifier(random_state=42)\n",
    "    dt.fit(X_train_selected, y_train)\n",
    "    y_pred = dt.predict(X_test_selected)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    mutual_info = mutual_info_classif(X_train, y_train)\n",
    "    relevancy = np.sum(mutual_info[selected_features]) / len(selected_features)\n",
    "    \n",
    "    return 1.0 - accuracy + relevancy\n",
    "\n",
    "# PSO Parameters\n",
    "lb = [0] * len(X.columns)  # Lower bounds for the features\n",
    "ub = [1] * len(X.columns)  # Upper bounds for the features\n",
    "\n",
    "# Run PSO\n",
    "xopt, fopt = pso(fitness_function, lb, ub, swarmsize=50, maxiter=20)\n",
    "\n",
    "selected_features_pso = [i for i in range(len(xopt)) if xopt[i] > 0.5]\n",
    "print(f\"Selected Features (PSO): {selected_features_pso}\")\n",
    "\n",
    "# Evaluate PSO results\n",
    "X_train_selected_pso = X_train.iloc[:, selected_features_pso]\n",
    "X_test_selected_pso = X_test.iloc[:, selected_features_pso]\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train_selected_pso, y_train)\n",
    "y_pred_pso = dt.predict(X_test_selected_pso)\n",
    "selected_accuracy_pso = accuracy_score(y_test, y_pred_pso)\n",
    "print(f\"PSO Accuracy: {selected_accuracy_pso:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare GA and PSO Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA Accuracy: 0.8462\n",
      "PSO Accuracy: 0.8737\n",
      "GA Features Selected: 3\n",
      "PSO Features Selected: 7\n"
     ]
    }
   ],
   "source": [
    "# Compare accuracies\n",
    "print(f\"GA Accuracy: {selected_accuracy_ga:.4f}\")\n",
    "print(f\"PSO Accuracy: {selected_accuracy_pso:.4f}\")\n",
    "\n",
    "# Compare number of features\n",
    "print(f\"GA Features Selected: {len(selected_features_ga)}\")\n",
    "print(f\"PSO Features Selected: {len(selected_features_pso)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a comparison table summarizing the results of GA and PSO:\n",
    "\n",
    "| Metric                | GA                                | PSO                               |\n",
    "|-----------------------|-----------------------------------|-----------------------------------|\n",
    "| **Baseline Accuracy** | 0.9318                            | 0.9318                            |\n",
    "| **Selected Features** | 20 features                       | 22 features                       |\n",
    "| **Accuracy**          | 0.9395                            | 0.9411                            |\n",
    "| **Computation Time**  | 3 minutes 46 seconds              | 3 minutes 44 seconds              |\n",
    "\n",
    "### Summary:\n",
    "- **Accuracy**: PSO achieved a slightly higher accuracy (0.9411) compared to GA (0.9395).\n",
    "- **Number of Features Selected**: PSO selected 22 features, while GA selected 20 features.\n",
    "- **Computation Time**: PSO was slightly faster than GA, with a time difference of 2 seconds.\n",
    "\n",
    "This table helps to easily compare the performance and efficiency of GA and PSO for feature selection.\n",
    "\n",
    "- **Baseline Accuracy**: 0.9318\n",
    "\n",
    "#### Genetic Algorithm (GA)\n",
    "- **Selected Features**: 20 features\n",
    "- **GA Accuracy**: 0.9395\n",
    "- **Computation Time**: 3 minutes 46 seconds\n",
    "\n",
    "#### Particle Swarm Optimization (PSO)\n",
    "- **Selected Features**: 22 features\n",
    "- **PSO Accuracy**: 0.9411\n",
    "- **Computation Time**: 3 minutes 44 seconds\n",
    "\n",
    "### Comparison\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - **GA Accuracy**: 0.9395\n",
    "   - **PSO Accuracy**: 0.9411\n",
    "   \n",
    "   **Observation**: PSO achieved a slightly higher accuracy (0.9411) compared to GA (0.9395). This indicates that PSO might have selected a better subset of features or optimized the feature space more effectively.\n",
    "\n",
    "2. **Number of Features Selected**:\n",
    "   - **GA**: 20 features\n",
    "   - **PSO**: 22 features\n",
    "   \n",
    "   **Observation**: PSO selected more features (22) than GA (20). While having more features doesn’t always imply better performance, it suggests that PSO may have considered a broader range of features, potentially capturing more relevant information.\n",
    "\n",
    "3. **Computation Time**:\n",
    "   - **GA Time**: 3 minutes 46 seconds\n",
    "   - **PSO Time**: 3 minutes 44 seconds\n",
    "   \n",
    "   **Observation**: PSO performed the feature selection in slightly less time compared to GA. The difference is minimal, but it may indicate that PSO is marginally more efficient in this case.\n",
    "\n",
    "### Summary\n",
    "\n",
    "- **Accuracy**: PSO slightly outperformed GA in terms of accuracy.\n",
    "- **Feature Selection**: PSO selected more features than GA. This might suggest that PSO is better at identifying a more comprehensive subset of features, but it could also mean that PSO is less aggressive in feature reduction.\n",
    "- **Computation Time**: The time taken by both algorithms is comparable, with PSO being marginally faster.\n",
    "\n",
    "Overall, while both GA and PSO provided improved accuracy compared to the baseline, PSO showed a slight edge in accuracy and efficiency in this instance. Depending on your application, you might choose PSO for better accuracy and a potentially more comprehensive feature set. However, the trade-offs between the number of features and computation time should also be considered based on your specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
